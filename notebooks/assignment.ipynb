{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6dbc95",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a1d6d",
   "metadata": {},
   "source": [
    "**Goal**: The goal of this assignment is to use the packages presented before, i.e. pydantic, pandera and optuna, in a real case scenario, where you want to train a model and find the best hyperparameters.\n",
    "\n",
    "Using an open source insurance dataset, we will do the different steps:\n",
    "* Validate the dataset, making sure it is prepared to train a model using pandera.\n",
    "* Validate the input parameters for the bayesian optimization using pydantic.\n",
    "\n",
    "**Table of contents**:\n",
    "1. [Validate the dataset using pandera](#1-validate-the-dataset-using-pandera)\n",
    "2. [Validate the parameters using pydantic](#2-validate-the-parameters-using-pydantic)\n",
    "3. [Bonus](#3-bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3501acb0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c53bebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent))  # adjust .parent depth so 'src' is findable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1e90c",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d0586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    Field,\n",
    "    StrictStr,\n",
    "    field_validator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b4818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminwallyn/Git/workshop-robust-hyperparam-tuning/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.train_utils import (\n",
    "    load_conf_parameters,\n",
    "    retrieve_data_w_features,\n",
    "    run_bayesian_optimization,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d16455",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e432369",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/01_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b28107",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b9912",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d798c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DATA_PATH}/fremotor1prem0304.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a677555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDpol</th>\n",
       "      <th>Year</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>DrivGender</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>LicenceNb</th>\n",
       "      <th>PayFreq</th>\n",
       "      <th>JobCode</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>VehClass</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehGas</th>\n",
       "      <th>VehUsage</th>\n",
       "      <th>Garage</th>\n",
       "      <th>Area</th>\n",
       "      <th>Region</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>PremTot</th>\n",
       "      <th>test_set</th>\n",
       "      <th>val_set</th>\n",
       "      <th>big_train_set</th>\n",
       "      <th>train_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000111.100</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Cohabiting</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Half-yearly</td>\n",
       "      <td>Private employee</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Cheaper</td>\n",
       "      <td>P10</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Private+trip to office</td>\n",
       "      <td>Closed zbox</td>\n",
       "      <td>A2</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>A</td>\n",
       "      <td>M1</td>\n",
       "      <td>144.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000113.100</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Cohabiting</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Annual</td>\n",
       "      <td>Other</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cheapest</td>\n",
       "      <td>P8</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Private+trip to office</td>\n",
       "      <td>Opened collective parking</td>\n",
       "      <td>A7</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>A</td>\n",
       "      <td>M2</td>\n",
       "      <td>215.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000113.100</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Cohabiting</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Half-yearly</td>\n",
       "      <td>Other</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cheaper</td>\n",
       "      <td>P11</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Private+trip to office</td>\n",
       "      <td>Opened collective parking</td>\n",
       "      <td>A7</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>A</td>\n",
       "      <td>M2</td>\n",
       "      <td>611.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000173.100</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Cohabiting</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Half-yearly</td>\n",
       "      <td>Private employee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cheaper</td>\n",
       "      <td>P11</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Private+trip to office</td>\n",
       "      <td>Closed zbox</td>\n",
       "      <td>A7</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>A</td>\n",
       "      <td>M1</td>\n",
       "      <td>415.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000173.101</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Cohabiting</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Half-yearly</td>\n",
       "      <td>Private employee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cheap</td>\n",
       "      <td>P13</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Private+trip to office</td>\n",
       "      <td>Closed collective parking</td>\n",
       "      <td>A7</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>A</td>\n",
       "      <td>M3</td>\n",
       "      <td>487.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IDpol    Year  DrivAge DrivGender MaritalStatus  BonusMalus  \\\n",
       "0  1000111.100  2003.0     44.0          F    Cohabiting        50.0   \n",
       "1  1000113.100  2003.0     26.0          F    Cohabiting        85.0   \n",
       "2  1000113.100  2003.0     27.0          F    Cohabiting       106.0   \n",
       "3  1000173.100  2003.0     52.0          M    Cohabiting        50.0   \n",
       "4  1000173.101  2003.0     52.0          M    Cohabiting        50.0   \n",
       "\n",
       "   LicenceNb      PayFreq           JobCode  VehAge  VehClass VehPower  \\\n",
       "0        3.0  Half-yearly  Private employee    10.0   Cheaper      P10   \n",
       "1        2.0       Annual             Other     8.0  Cheapest       P8   \n",
       "2        2.0  Half-yearly             Other     6.0   Cheaper      P11   \n",
       "3        2.0  Half-yearly  Private employee     2.0   Cheaper      P11   \n",
       "4        2.0  Half-yearly  Private employee     1.0     Cheap      P13   \n",
       "\n",
       "    VehGas                VehUsage                     Garage Area  \\\n",
       "0  Regular  Private+trip to office                Closed zbox   A2   \n",
       "1  Regular  Private+trip to office  Opened collective parking   A7   \n",
       "2  Regular  Private+trip to office  Opened collective parking   A7   \n",
       "3  Regular  Private+trip to office                Closed zbox   A7   \n",
       "4  Regular  Private+trip to office  Closed collective parking   A7   \n",
       "\n",
       "         Region Channel Marketing  PremTot  test_set  val_set  big_train_set  \\\n",
       "0  Headquarters       A        M1    144.1         1        0              0   \n",
       "1  Headquarters       A        M2    215.3         1        0              0   \n",
       "2  Headquarters       A        M2    611.6         1        0              0   \n",
       "3  Headquarters       A        M1    415.2         0        0              1   \n",
       "4  Headquarters       A        M3    487.8         0        0              1   \n",
       "\n",
       "   train_set  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e9022",
   "metadata": {},
   "source": [
    "# 1. Validate the dataset using pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d6d65",
   "metadata": {},
   "source": [
    "**Goal**: The goal of this section is to validate the dataframe we will use to train our model.\n",
    "\n",
    "We want to validate the dataframe before training our model. Your goal is to make sure the columns will verify the following rules:\n",
    "* **Year**: Check the year are between 2003 and 2004.\n",
    "* **DrivAge**: Make sure the driver's age are possible (e.g. between 18 and 100).\n",
    "* **DrivGender**: The gender is either 'M' or 'F'.\n",
    "* **MaritalStatus**: Possible values \"Cohabiting\", \"Married\", \"Single\", \"Widowed\" or \"Divorced\".\n",
    "* **BonusMalus**: The value of the bonus / malus is over 50.\n",
    "* **LicenceNb**: The licence number is over 1.\n",
    "* **JobCode**: The possible values are \"Private employee\", \"Public employee\", \"Retiree\", \"Other\", \"Craftsman\", \"Farmer\" or \"Retailer\",\n",
    "* **VehAge**: Make sure the vehicule age is possible.\n",
    "* **VehGas**: Either \"Regular\" or \"Diesel\".\n",
    "* **Area**: Possible values are from A1 to A12 included.\n",
    "\n",
    "**Exercise**: Update the schema to check the rules defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50fb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c51faf",
   "metadata": {},
   "source": [
    "However, as you can see, some features contain NaN values. To handle this issue, you have several solutions:\n",
    "* In the dataframe schema from pandera, set the option of possible NaN values to True. We don't recommend this approach as many models can't handle NaN values or you want to make sure to use them properly.\n",
    "* You can set the option in the pandera schema to drop rows with NaN values.\n",
    "* You can handle it with the classical feature engineering technics (feature imputing, creating new category, etc.)\n",
    "\n",
    "**Exercise**: Create a function to handle missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c7f3d",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click to reveal tip</summary>\n",
    "\n",
    "Use the `mode()[0]` function to get the most represented category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f93692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe3242",
   "metadata": {},
   "source": [
    "To train the model, splitting the dataset between train, validation and test sets is important. You want to make sure each row is splitted into one and only one of the sets. To do so, you can use custom functions from pandera.\n",
    "\n",
    "**Exercise**: Adapt the schema to check that each row is in one and only one set.\n",
    "1. Add the right checks for the columns `train_set`, `val_set` and `test_set`.\n",
    "2. Add a schema check to make sure that each row is assigned to one and only one set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6d250",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click to reveal tip</summary>\n",
    "\n",
    "Use the `checks` parameter of the schema directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28a31af",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcebf4de",
   "metadata": {},
   "source": [
    "We also have the `big_train_set` column which indicates rows contained in the train or validation sets.\n",
    "\n",
    "**Exercise**: Adapt the schema to check that rows in either train or validation sets are in the big train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31ab46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff84dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "def fill_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fill missing values.\n",
    "\n",
    "    Fill the missing values in the 'JobCode' and 'MaritalStatus' columns with the mode\n",
    "    (most frequent value) of their respective columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with potential missing values.\n",
    "    \"\"\"\n",
    "    df[\"JobCode\"] = df[\"JobCode\"].fillna(df[\"JobCode\"].mode()[0])\n",
    "    df[\"MaritalStatus\"] = df[\"MaritalStatus\"].fillna(df[\"MaritalStatus\"].mode()[0])\n",
    "    return df\n",
    "\n",
    "schema_df = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"IDpol\": pa.Column(str),\n",
    "        \"PayFreq\": pa.Column(str, checks=pa.Check.isin([\"Annual\", \"Half-yearly\", \"Quarterly\", \"Monthly\"])),\n",
    "        \"VehClass\": pa.Column(str, checks=pa.Check.isin([\n",
    "            \"Cheapest\", \"Cheaper\", \"Cheap\", \"Medium low\", \"Medium\", \"Medium high\", \"Expensive\", \"More expensive\", \"Most expensive\",\n",
    "        ])),\n",
    "        \"VehPower\": pa.Column(str, checks=pa.Check.isin([f\"P{i}\" for i in range(1, 21)])),\n",
    "        \"VehUsage\": pa.Column(str, checks=pa.Check.isin([\n",
    "            \"Private+trip to office\", \"Professional\", \"Professional run\",\n",
    "        ])),\n",
    "        \"Garage\": pa.Column(str, checks=pa.Check.isin([\n",
    "            \"Closed zbox\", \"Closed collective parking\", \"Opened collective parking\", \"Street\",\n",
    "        ])),\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        \"Year\": pa.Column(int, checks=[pa.Check.ge(2003), pa.Check.le(2004)], coerce=True),\n",
    "        \"DrivAge\": pa.Column(int, checks=[pa.Check.ge(18), pa.Check.le(100)], coerce=True),\n",
    "        \"DrivGender\": pa.Column(str, checks=pa.Check.isin([\"M\", \"F\"])),\n",
    "        \"MaritalStatus\": pa.Column(str, checks=pa.Check.isin([\n",
    "            \"Cohabiting\", \"Married\", \"Single\", \"Widowed\", \"Divorced\",\n",
    "        ])),\n",
    "        \"BonusMalus\": pa.Column(int, checks=pa.Check.ge(50), coerce=True),\n",
    "        \"LicenceNb\": pa.Column(int, checks=pa.Check.ge(1), coerce=True),\n",
    "        \"JobCode\": pa.Column(str, checks=pa.Check.isin([\n",
    "            \"Private employee\", \"Public employee\", \"Retiree\", \"Other\", \"Craftsman\", \"Farmer\", \"Retailer\", \"Unknown\",\n",
    "        ])),\n",
    "        \"VehAge\": pa.Column(int, checks=pa.Check.ge(0), coerce=True),\n",
    "        \"VehGas\": pa.Column(str, checks=pa.Check.isin([\"Regular\", \"Diesel\"])),\n",
    "        \"Area\": pa.Column(str, checks=pa.Check.isin([f\"A{i}\" for i in range(1, 13)])),\n",
    "        # Sets for the model\n",
    "        \"train_set\": pa.Column(int, checks=pa.Check.isin([0, 1])),\n",
    "        \"val_set\": pa.Column(int, checks=pa.Check.isin([0, 1])),\n",
    "        \"test_set\": pa.Column(int, checks=pa.Check.isin([0, 1])),\n",
    "        \"big_train_set\": pa.Column(int, checks=pa.Check.isin([0, 1])),\n",
    "    },\n",
    "    checks=[\n",
    "        pa.Check(\n",
    "            lambda df: (df[[\"train_set\", \"val_set\", \"test_set\"]].sum(axis=1) == 1).all(),\n",
    "            error=\"Exactly one and only of the train_set, val_set and test_set must be 1 for each row.\",\n",
    "        ),\n",
    "        pa.Check(\n",
    "            lambda df: (\n",
    "                (df[\"big_train_set\"] == ((df[\"train_set\"] == 1) | (df[\"val_set\"] == 1)).astype(int))\n",
    "            ).all(),\n",
    "            error=\"big_train_set must be 1 if either train_set or valid_set is 1, and 0 otherwise.\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_filled = fill_missing_values(df)\n",
    "\n",
    "df_validated = schema_df.validate(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9ebf9",
   "metadata": {},
   "source": [
    "# 2. Validate the parameters using pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbf6cc",
   "metadata": {},
   "source": [
    "**Goal**: The goal of this section is to display a real use of the pydantic validations to check that the parameters passed to your code are ones you accept.\n",
    "The validations will be applied to parameters to use for the optuna modelisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f160f15",
   "metadata": {},
   "source": [
    "**Exercise**: Create a pydantic class to validate the parameters given in a conf file to make sure they respect some rules to catch bugs before running your code:\n",
    "1. Define the attribute `search_space` which represents the search space for the Bayesian optimization.\n",
    "2. Define the attribute `categorical_feat` which represents the categorical features.\n",
    "3. Define the attribute `default_params` which represents the default combination of hyperparameters to test at the beginning of the Bayesian optimization.\n",
    "4. Create a custom validator to validate the `search_space`. The search space should be a dict where the keys are parameters names and the values are dict containing:\n",
    "   * `sampling_type`: The type of the parameter. Should be `categorical`, `int` or `float`.\n",
    "   * If the sampling type is categorical, an element `choices` containing the possible values.\n",
    "   * If the sampling type is either int or float, elements `min` and `max` containing the minimum and maximum values for the search space.\n",
    "\n",
    "For example:\n",
    "```yaml\n",
    "search_space: {\n",
    "    \"param_1\": {\n",
    "        \"sampling_type\": \"categorical\",\n",
    "        \"choices\": [\"cat_1\", \"cat_2\"],\n",
    "    },\n",
    "    \"param_2\":{\n",
    "        \"sampling_type\": \"int\",\n",
    "        \"min\": min_val,\n",
    "        \"max\": max_val,\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999d3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "class validate_input_parameters(BaseModel):\n",
    "    \"\"\"A pydantic class to validate the input parameters of the process.\"\"\"\n",
    "    target_name: StrictStr = Field(\n",
    "        pattern=r\"^[A-Za-z0-1\\_]+$\",\n",
    "        description=\"Name of the target column.\",\n",
    "        frozen=True,\n",
    "    )\n",
    "    # ========================\n",
    "    # ==== YOUR CODE HERE ====\n",
    "    # ========================\n",
    "    search_space: dict[str, dict[StrictStr, Any]] = Field(\n",
    "        description=\"Search space for the Bayesian optimization.\",\n",
    "        frozen=True,\n",
    "    )\n",
    "    categorical_feat: list[StrictStr] = Field(\n",
    "        description=\"List of the categorical features\",\n",
    "        frozen=True,\n",
    "    )\n",
    "    default_params: list[dict[StrictStr, Any]] = Field(\n",
    "        description=\"List of combination of default parameters to check at the beginning of the bayesian optimization.\",\n",
    "        frozen=True,\n",
    "    )\n",
    "\n",
    "    @field_validator(\"search_space\")\n",
    "    @classmethod\n",
    "    def validate_search_space(cls, value: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Validate the search space parameter for the bayesian optimization.\"\"\"\n",
    "        for hyparam_name, sampling_params in value.items():\n",
    "            if sampling_params[\"sampling_type\"] == \"categorical\":\n",
    "                # For categorical parameters\n",
    "                if \"choices\" not in sampling_params.keys():\n",
    "                    raise KeyError(\n",
    "                        f\"Check {hyparam_name}. For a categorical feature, you should provide a 'choices' parameter for the possible values.\"\n",
    "                    )\n",
    "            elif sampling_params[\"sampling_type\"] in [\"float\", \"int\"]:\n",
    "                # For continuous parameters\n",
    "                if (\"min\" not in sampling_params.keys()) | (\"max\" not in sampling_params.keys()):\n",
    "                    raise KeyError(f\"Check {hyparam_name}. For continuous parameters, you should provide 'min' and 'max' parameters.\")\n",
    "            else:\n",
    "                raise ValueError(f\"Check {hyparam_name}. Sampling type should be either 'categorical', 'int' or 'float'. You provided {sampling_params['sampling_type']}.\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b77c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_conf_parameters(\"../conf/parameters.yml\")\n",
    "\n",
    "validated_params = validate_input_parameters(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b237f20",
   "metadata": {},
   "source": [
    "As you can see, some parameters don't follow the rules you defined in the pydantic class!\n",
    "\n",
    "**Exercise**: Fix the parameters in the conf file to follow rules you defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2adf3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### ACTIONS TO DO ###\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84957e3a",
   "metadata": {},
   "source": [
    "Then, we can run the Bayesian optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e19815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminwallyn/Git/workshop-robust-hyperparam-tuning/.venv/lib/python3.13/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-11-01 22:20:52,407] A new study created in memory with name: basic_hgb_opt\n",
      "Best trial: 0. Best value: 107.462:   2%|▏         | 1/50 [00:00<00:25,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:52,939] Trial 0 finished with value: 107.46195150088059 and parameters: {'max_iter': 50, 'learning_rate': 0.1, 'l2_regularization': 1.0}. Best is trial 0 with value: 107.46195150088059.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 107.462:   4%|▍         | 2/50 [00:00<00:17,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:53,200] Trial 1 finished with value: 112.03645313813234 and parameters: {'max_iter': 44, 'learning_rate': 0.4758500101408589, 'l2_regularization': 7.319939418114051}. Best is trial 0 with value: 107.46195150088059.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 107.462:   8%|▊         | 4/50 [00:01<00:15,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:53,776] Trial 2 finished with value: 107.6255301759693 and parameters: {'max_iter': 64, 'learning_rate': 0.0864491338167939, 'l2_regularization': 1.5599452033620265}. Best is trial 0 with value: 107.46195150088059.\n",
      "[I 2025-11-01 22:20:53,940] Trial 3 finished with value: 110.92010670995604 and parameters: {'max_iter': 15, 'learning_rate': 0.4344263114297182, 'l2_regularization': 6.011150117432088}. Best is trial 0 with value: 107.46195150088059.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 107.462:  10%|█         | 5/50 [00:02<00:19,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:54,531] Trial 4 finished with value: 129.94096366108002 and parameters: {'max_iter': 74, 'learning_rate': 0.020086402204943198, 'l2_regularization': 9.699098521619943}. Best is trial 0 with value: 107.46195150088059.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  12%|█▏        | 6/50 [00:02<00:22,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:55,225] Trial 5 finished with value: 106.84609860409188 and parameters: {'max_iter': 85, 'learning_rate': 0.11404616423235532, 'l2_regularization': 1.8182496720710062}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  14%|█▍        | 7/50 [00:03<00:18,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:55,482] Trial 6 finished with value: 109.50634730773871 and parameters: {'max_iter': 26, 'learning_rate': 0.1590786990501735, 'l2_regularization': 5.247564316322379}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  16%|█▌        | 8/50 [00:03<00:18,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:55,910] Trial 7 finished with value: 107.45742830522933 and parameters: {'max_iter': 49, 'learning_rate': 0.15270227869704053, 'l2_regularization': 6.118528947223795}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  18%|█▊        | 9/50 [00:03<00:15,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:56,148] Trial 8 finished with value: 111.21175632629901 and parameters: {'max_iter': 22, 'learning_rate': 0.1531508777822569, 'l2_regularization': 3.663618432936917}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  20%|██        | 10/50 [00:04<00:13,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:56,420] Trial 9 finished with value: 109.83175380780865 and parameters: {'max_iter': 51, 'learning_rate': 0.39473622108257667, 'l2_regularization': 1.9967378215835974}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  22%|██▏       | 11/50 [00:04<00:14,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:56,836] Trial 10 finished with value: 108.86838007340613 and parameters: {'max_iter': 88, 'learning_rate': 0.2666512384238821, 'l2_regularization': 1.9100360148552773}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  24%|██▍       | 12/50 [00:04<00:14,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:57,300] Trial 11 finished with value: 107.43423931079255 and parameters: {'max_iter': 69, 'learning_rate': 0.20890065115787296, 'l2_regularization': 5.1301740183834}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  26%|██▌       | 13/50 [00:05<00:18,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:58,041] Trial 12 finished with value: 107.13904459798019 and parameters: {'max_iter': 87, 'learning_rate': 0.06139327730628868, 'l2_regularization': 4.328178827638933}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  28%|██▊       | 14/50 [00:06<00:21,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:58,859] Trial 13 finished with value: 116.76261914535365 and parameters: {'max_iter': 92, 'learning_rate': 0.025307360781797038, 'l2_regularization': 3.5558401810541027}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  30%|███       | 15/50 [00:06<00:18,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:59,228] Trial 14 finished with value: 108.80929553974754 and parameters: {'max_iter': 99, 'learning_rate': 0.2831704031116692, 'l2_regularization': 6.337285824550085}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  32%|███▏      | 16/50 [00:07<00:17,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:20:59,722] Trial 15 finished with value: 107.9370903554084 and parameters: {'max_iter': 94, 'learning_rate': 0.14975678508771134, 'l2_regularization': 2.140303555110155}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 106.846:  34%|███▍      | 17/50 [00:08<00:18,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:00,429] Trial 16 finished with value: 109.69859076268779 and parameters: {'max_iter': 84, 'learning_rate': 0.04399863776813073, 'l2_regularization': 0.23778048215570902}. Best is trial 5 with value: 106.84609860409188.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  36%|███▌      | 18/50 [00:08<00:20,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:01,236] Trial 17 finished with value: 106.75318289641064 and parameters: {'max_iter': 96, 'learning_rate': 0.0845937826354282, 'l2_regularization': 6.105017128867974}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  38%|███▊      | 19/50 [00:09<00:19,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:01,871] Trial 18 finished with value: 107.0392378047381 and parameters: {'max_iter': 97, 'learning_rate': 0.11584002813593608, 'l2_regularization': 7.376377086559808}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  40%|████      | 20/50 [00:10<00:18,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:02,483] Trial 19 finished with value: 110.94916045518733 and parameters: {'max_iter': 66, 'learning_rate': 0.052394046583764654, 'l2_regularization': 6.47037064871913}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  42%|████▏     | 21/50 [00:10<00:15,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:02,805] Trial 20 finished with value: 109.94283456963805 and parameters: {'max_iter': 90, 'learning_rate': 0.34841480730860025, 'l2_regularization': 9.119167232179375}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  44%|████▍     | 22/50 [00:11<00:16,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:03,543] Trial 21 finished with value: 106.97267978827404 and parameters: {'max_iter': 97, 'learning_rate': 0.1441711308016249, 'l2_regularization': 9.699006798352707}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  46%|████▌     | 23/50 [00:11<00:15,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:04,056] Trial 22 finished with value: 107.55801568106776 and parameters: {'max_iter': 84, 'learning_rate': 0.21945644488000626, 'l2_regularization': 9.379654940376533}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  48%|████▊     | 24/50 [00:12<00:16,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:04,831] Trial 23 finished with value: 108.7542925203563 and parameters: {'max_iter': 97, 'learning_rate': 0.04676474764226714, 'l2_regularization': 9.438482094909256}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  50%|█████     | 25/50 [00:13<00:16,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:05,610] Trial 24 finished with value: 108.2322950128373 and parameters: {'max_iter': 100, 'learning_rate': 0.04763102887084621, 'l2_regularization': 5.775024427721742}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  52%|█████▏    | 26/50 [00:13<00:15,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:06,162] Trial 25 finished with value: 107.48530071298948 and parameters: {'max_iter': 96, 'learning_rate': 0.2024855414275002, 'l2_regularization': 9.993624386415512}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  54%|█████▍    | 27/50 [00:14<00:13,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:06,685] Trial 26 finished with value: 108.00930134394194 and parameters: {'max_iter': 73, 'learning_rate': 0.18272486611478012, 'l2_regularization': 1.9607594542555924}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  56%|█████▌    | 28/50 [00:14<00:10,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:06,917] Trial 27 finished with value: 167.82510489356608 and parameters: {'max_iter': 23, 'learning_rate': 0.02366256256976662, 'l2_regularization': 8.609673685680681}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  58%|█████▊    | 29/50 [00:14<00:10,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:07,402] Trial 28 finished with value: 107.29401910431827 and parameters: {'max_iter': 94, 'learning_rate': 0.15119393423714608, 'l2_regularization': 5.520321531256846}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  60%|██████    | 30/50 [00:15<00:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:07,805] Trial 29 finished with value: 108.63748684887928 and parameters: {'max_iter': 60, 'learning_rate': 0.29754633374899386, 'l2_regularization': 8.541254843274125}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  62%|██████▏   | 31/50 [00:16<00:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:08,466] Trial 30 finished with value: 106.99074683947958 and parameters: {'max_iter': 85, 'learning_rate': 0.1452616211921068, 'l2_regularization': 8.961420499493203}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  64%|██████▍   | 32/50 [00:16<00:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:09,097] Trial 31 finished with value: 107.14882856940676 and parameters: {'max_iter': 83, 'learning_rate': 0.14076281760878637, 'l2_regularization': 9.804797870788795}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  66%|██████▌   | 33/50 [00:17<00:09,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:09,580] Trial 32 finished with value: 107.35528166971592 and parameters: {'max_iter': 87, 'learning_rate': 0.16223967781662307, 'l2_regularization': 7.41153191179948}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  70%|███████   | 35/50 [00:17<00:06,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:10,249] Trial 33 finished with value: 107.00601771726296 and parameters: {'max_iter': 81, 'learning_rate': 0.10624828710274628, 'l2_regularization': 8.186352307485334}. Best is trial 17 with value: 106.75318289641064.\n",
      "[I 2025-11-01 22:21:10,397] Trial 34 finished with value: 113.41947650857344 and parameters: {'max_iter': 12, 'learning_rate': 0.22201982983363633, 'l2_regularization': 0.10989189243771236}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 106.753:  72%|███████▏  | 36/50 [00:18<00:06,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:10,802] Trial 35 finished with value: 107.80594700669182 and parameters: {'max_iter': 35, 'learning_rate': 0.22866961438205535, 'l2_regularization': 9.826861567778046}. Best is trial 17 with value: 106.75318289641064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 106.626:  74%|███████▍  | 37/50 [00:19<00:06,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:11,512] Trial 36 finished with value: 106.62567495958235 and parameters: {'max_iter': 98, 'learning_rate': 0.13127891494843358, 'l2_regularization': 8.326217135905448}. Best is trial 36 with value: 106.62567495958235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 106.626:  76%|███████▌  | 38/50 [00:19<00:06,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:12,084] Trial 37 finished with value: 106.68151680977583 and parameters: {'max_iter': 94, 'learning_rate': 0.12548829562855865, 'l2_regularization': 7.536655492734865}. Best is trial 36 with value: 106.62567495958235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 106.626:  78%|███████▊  | 39/50 [00:20<00:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:12,911] Trial 38 finished with value: 110.12909239248403 and parameters: {'max_iter': 88, 'learning_rate': 0.042748174449258686, 'l2_regularization': 7.2153791014055955}. Best is trial 36 with value: 106.62567495958235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 106.626:  80%|████████  | 40/50 [00:20<00:05,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:13,257] Trial 39 finished with value: 112.43983975412435 and parameters: {'max_iter': 88, 'learning_rate': 0.49641180536051777, 'l2_regularization': 6.605992458284577}. Best is trial 36 with value: 106.62567495958235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 36. Best value: 106.626:  82%|████████▏ | 41/50 [00:21<00:04,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:13,818] Trial 40 finished with value: 107.23473141540659 and parameters: {'max_iter': 99, 'learning_rate': 0.19312783362336472, 'l2_regularization': 7.325055474542392}. Best is trial 36 with value: 106.62567495958235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  84%|████████▍ | 42/50 [00:22<00:05,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:14,880] Trial 41 finished with value: 106.43685626802875 and parameters: {'max_iter': 99, 'learning_rate': 0.09475222987703978, 'l2_regularization': 7.2322349454003865}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  86%|████████▌ | 43/50 [00:23<00:04,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:15,570] Trial 42 finished with value: 107.44122838004272 and parameters: {'max_iter': 84, 'learning_rate': 0.14106613498700257, 'l2_regularization': 6.810825258326328}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  88%|████████▊ | 44/50 [00:23<00:04,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:16,415] Trial 43 finished with value: 107.04758826925774 and parameters: {'max_iter': 97, 'learning_rate': 0.06623011418423239, 'l2_regularization': 7.615790612507069}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  90%|█████████ | 45/50 [00:24<00:03,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:16,695] Trial 44 finished with value: 108.70427410343304 and parameters: {'max_iter': 27, 'learning_rate': 0.3117889135605332, 'l2_regularization': 3.7734415134720214}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  92%|█████████▏| 46/50 [00:24<00:02,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:17,012] Trial 45 finished with value: 157.89615456763977 and parameters: {'max_iter': 31, 'learning_rate': 0.021880743737880598, 'l2_regularization': 0.41965122581661696}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  94%|█████████▍| 47/50 [00:25<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:17,738] Trial 46 finished with value: 115.97034336650506 and parameters: {'max_iter': 68, 'learning_rate': 0.03510119033483587, 'l2_regularization': 2.6612496300705093}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 106.437:  96%|█████████▌| 48/50 [00:26<00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:18,610] Trial 47 finished with value: 106.55940045978865 and parameters: {'max_iter': 99, 'learning_rate': 0.11393554064054226, 'l2_regularization': 6.356501870689687}. Best is trial 41 with value: 106.43685626802875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 106.114:  98%|█████████▊| 49/50 [00:27<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:19,533] Trial 48 finished with value: 106.11371766638698 and parameters: {'max_iter': 94, 'learning_rate': 0.14650511854697806, 'l2_regularization': 4.80666423314504}. Best is trial 48 with value: 106.11371766638698.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 48. Best value: 106.114: 100%|██████████| 50/50 [00:27<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-01 22:21:20,198] Trial 49 finished with value: 106.97829670481916 and parameters: {'max_iter': 96, 'learning_rate': 0.17971247269577406, 'l2_regularization': 5.583428202094666}. Best is trial 48 with value: 106.11371766638698.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_iter': 94,\n",
       " 'learning_rate': 0.14650511854697806,\n",
       " 'l2_regularization': 4.80666423314504}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = [\"IDpol\", \"Year\", \"train_set\", \"val_set\", \"test_set\", \"big_train_set\"]\n",
    "\n",
    "X_big_train, y_big_train = retrieve_data_w_features(df=df, features_to_drop=cols_to_drop, split=\"big_train_set\")\n",
    "X_train, y_train = retrieve_data_w_features(df=df, features_to_drop=cols_to_drop, split=\"train_set\")\n",
    "X_val, y_val = retrieve_data_w_features(df=df, features_to_drop=cols_to_drop, split=\"val_set\")\n",
    "X_test, y_test = retrieve_data_w_features(df=df, features_to_drop=cols_to_drop, split=\"test_set\")\n",
    "\n",
    "best_params = run_bayesian_optimization(\n",
    "    df_train=X_train,\n",
    "    y_train=y_train,\n",
    "    df_val=X_val,\n",
    "    y_val=y_val,\n",
    "    categorical_features=validated_params.categorical_feat,\n",
    "    search_params=validated_params.search_space,\n",
    "    default_params_list=validated_params.default_params,\n",
    ")\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e2c719",
   "metadata": {},
   "source": [
    "Now that we have found the best hyperparameters, we can train on the big train set and evaluate on the test set!\n",
    "\n",
    "**Exercise**: Train a final model on the big train set using the best hyperparameters and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3439324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big Train RMSE: 87.34474200996922\n",
      "Test RMSE: 103.72454358053689\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "model = HistGradientBoostingRegressor(\n",
    "    categorical_features=validated_params.categorical_feat,\n",
    "    early_stopping=True,\n",
    "    random_state=42,\n",
    "    **best_params,\n",
    ")\n",
    "model.fit(X=X_big_train, y=y_big_train, X_val=X_test, y_val=y_test)\n",
    "\n",
    "big_train_predictions = model.predict(X_big_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "big_train_rmse = root_mean_squared_error(y_true=y_big_train, y_pred=big_train_predictions)\n",
    "print(f\"Big Train RMSE: {big_train_rmse}\")\n",
    "test_rmse = root_mean_squared_error(y_true=y_test, y_pred=test_predictions)\n",
    "print(f\"Test RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ea444",
   "metadata": {},
   "source": [
    "# 3. Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db4fca",
   "metadata": {},
   "source": [
    "You can see that there is overfitting! \n",
    "\n",
    "**Exercise**: Modify the function in the `train_utils.py` file to limit the overfitting of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879aea2",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click to reveal tip 1</summary>\n",
    "\n",
    "Add an element in the metric to optimize containing the delta between train and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ac360",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click to reveal tip 2</summary>\n",
    "\n",
    "Use an alpha parameter to control the impact of this delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c7e6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import optuna\n",
    "import numpy as np\n",
    "from src.train_utils import build_search_space\n",
    "\n",
    "def optimize_hyperparams_hgb(\n",
    "    trial: optuna.trial.Trial,\n",
    "    search_params: dict[str, Any],\n",
    "    df_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    df_val: pd.DataFrame,\n",
    "    y_val: pd.Series,\n",
    "    categorical_features: list[str],\n",
    "    alpha: float = 0.3\n",
    ") -> float:\n",
    "    \"\"\"Optimize the hyperparameters of the HistGradientBoosting model.\n",
    "    \n",
    "    Args:\n",
    "        trial (optuna.trial.Trial): The Optuna trial object.\n",
    "        search_params (dict[str, Any]): The search space parameters.\n",
    "        df_train (pd.DataFrame): The training features.\n",
    "        y_train (pd.Series): The training target.\n",
    "        df_val (pd.DataFrame): The validation features.\n",
    "        y_val (pd.Series): The validation target.\n",
    "        categorical_features (list[str]): List of categorical feature names.\n",
    "\n",
    "    Returns:\n",
    "        (float): The validation loss.\n",
    "    \"\"\"\n",
    "    # Build search space\n",
    "    hyperparams = build_search_space(trial, search_params)\n",
    "\n",
    "    # Define the model\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        categorical_features=categorical_features,\n",
    "        early_stopping=True,\n",
    "        random_state=42,\n",
    "        **hyperparams,\n",
    "    )\n",
    "    model.fit(X=df_train, y=y_train, X_val=df_val, y_val=y_val)\n",
    "    val_predictions = model.predict(df_val)\n",
    "    rmse_train = root_mean_squared_error(y_true=y_train, y_pred=model.predict(df_train))\n",
    "    rmse_val = root_mean_squared_error(y_true=y_val, y_pred=val_predictions)\n",
    "\n",
    "    return rmse_val + alpha * np.abs(rmse_train - rmse_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
