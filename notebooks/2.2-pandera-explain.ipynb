{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d71dba48",
   "metadata": {},
   "source": [
    "# Explain Pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf65e74",
   "metadata": {},
   "source": [
    "Take a look at the [documentation](https://pandera.readthedocs.io/en/stable/index.html).\n",
    "\n",
    "Pandera is a Union.ai open source project that provides a flexible and expressive API for performing data validation on dataframe-like objects. The goal of Pandera is to make data processing pipelines more readable and robust with statistically typed dataframes.\n",
    "\n",
    "Dataframes contain information that pandera explicitly validates at runtime. This is useful in production-critical data pipelines or reproducible research settings. With pandera, you can:\n",
    "- Define a schema once and use it to validate different dataframe types including pandas, polars, dask, modin, ibis, and pyspark.\n",
    "- Check the types and properties of columns in a pd.DataFrame or values in a pd.Series.\n",
    "- Perform more complex statistical validation like hypothesis testing.\n",
    "- Parse data to standardize the preprocessing steps needed to produce valid data.\n",
    "- Seamlessly integrate with existing data analysis/processing pipelines via function decorators.\n",
    "- Define dataframe models with the class-based API with pydantic-style syntax and validate dataframes using the typing syntax.\n",
    "- Synthesize data from schema objects for property-based testing with pandas data structures.\n",
    "- Lazily Validate dataframes so that all validation rules are executed before raising an error.\n",
    "- Integrate with a rich ecosystem of python tools like pydantic, fastapi and mypy.\n",
    "\n",
    "Pandera supports multiple dataframe libraries, including pandas, polars, pyspark, and ibis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf6357",
   "metadata": {},
   "source": [
    "**Table of contents**:\n",
    "1. [Explain Pandera](#1-explain-pandera)\n",
    "   1. [Validate dataframe schema](#11-validate-dataframe-schema)\n",
    "   2. [Column validation](#12-column-validation)\n",
    "      1. [First validations](#121-first-validations)\n",
    "      2. [Null values](#122-null-values)\n",
    "      3. [Coercing types on columns](#123-coercing-types-on-columns)\n",
    "      4. [Required columns](#124-required-columns)\n",
    "      5. [Column regex pattern](#125-column-regex-pattern)\n",
    "      6. [Validation the joint uniqueness of columns](#126-validating-the-joint-uniqueness-of-columns)\n",
    "2. [Handling errors](#2-handling-errors)\n",
    "   1. [Missing and required columns](#21-missing-and-required-columns)\n",
    "      1. [Handling dataframe columns not in the schema](#211-handling-dataframe-columns-not-in-the-schema)\n",
    "      2. [Adding missing columns](#212-adding-missing-columns)\n",
    "   2. [Error reports](#22-error-reports)\n",
    "3. [Synthesize data](#3-synthesize-data)\n",
    "   1. [Basic usage](#31-basic-usage)\n",
    "   2. [Usage in unit tests](#32-usage-in-unit-tests)\n",
    "4. [Supported features by DataFrame backend](#4-supported-features-by-dataframe-backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bdc09",
   "metadata": {},
   "source": [
    "# 1. Explain Pandera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec79ad48",
   "metadata": {},
   "source": [
    "## 1.1 Validate dataframe schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab82cf",
   "metadata": {},
   "source": [
    "Pandera is a good way to validate to validate the quality of the data. We highly recommend using it before you train your model.\n",
    "\n",
    "Let's take a first example where you want to validate a dataframe. There are 3 columns with different types we want to validate: int, float and string. To do so, you first define a `pa.DataFrameSchema()` in which you will define the columns using `pa.Column(<type>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3208d324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column1  column2 column3\n",
      "0        1      1.1       a\n",
      "1        2      1.2       b\n",
      "2        3      1.3       c\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "# data to validate\n",
    "df = pd.DataFrame({\n",
    "    \"column1\": [1, 2, 3],\n",
    "    \"column2\": [1.1, 1.2, 1.3],\n",
    "    \"column3\": [\"a\", \"b\", \"c\"],\n",
    "})\n",
    "\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int),\n",
    "    \"column2\": pa.Column(float),\n",
    "    \"column3\": pa.Column(str),\n",
    "})\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21ea10",
   "metadata": {},
   "source": [
    "If you provide a dataframe with the wrong type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48cf7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected series 'column1' to have type int64, got float64\n"
     ]
    }
   ],
   "source": [
    "df_bug = pd.DataFrame({\n",
    "    \"column1\": [1, 2, 0.4],\n",
    "    \"column2\": [1.1, 1.2, 1.3],\n",
    "    \"column3\": [\"a\", \"b\", \"c\"],\n",
    "})\n",
    "\n",
    "try:\n",
    "    schema.validate(df_bug)\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe948680",
   "metadata": {},
   "source": [
    "## 1.2 Column validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ad63b",
   "metadata": {},
   "source": [
    "A `Column` must specify the properties of a column in a dataframe object. It can be optionally verified for its data type, [null values] or duplicate values. The column can be coerced into the specified type, and the [required] parameter allows control over whether or not the column is allowed to be missing.\n",
    "\n",
    "Similarly to pandas, the data type can be specified as:\n",
    "* a string alias, as long as it is recognized by pandas.\n",
    "* a python type: int, float, double, bool, str\n",
    "* a numpy data type\n",
    "* a pandas extension type: it can be an instance (e.g pd.CategoricalDtype([\"a\", \"b\"])) or a class (e.g pandas.CategoricalDtype) if it can be initialized with default values.\n",
    "* a pandera DataType: it can also be an instance or a class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24884d0b",
   "metadata": {},
   "source": [
    "### 1.2.1 First validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3db56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int, pa.Check.ge(0)),\n",
    "    \"column2\": pa.Column(float, pa.Check.lt(10)),\n",
    "    \"column3\": pa.Column(\n",
    "        str,\n",
    "        [\n",
    "            pa.Check.isin([*\"abc\"]),\n",
    "            pa.Check(lambda series: series.str.len() == 1),\n",
    "        ]\n",
    "    ),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f7a5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column1  column2 column3\n",
      "0        1      1.1       a\n",
      "1        2      1.2       b\n",
      "2        3      1.3       c\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"column1\": [1, 2, 3],\n",
    "    \"column2\": [1.1, 1.2, 1.3],\n",
    "    \"column3\": [\"a\", \"b\", \"c\"],\n",
    "})\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "print(validated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5da3de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'column2' failed element-wise validator number 0: less_than(10) failure cases: 12.3\n"
     ]
    }
   ],
   "source": [
    "df_bug = pd.DataFrame({\n",
    "    \"column1\": [1, 2, 3],\n",
    "    \"column2\": [1.1, 1.2, 12.3],\n",
    "    \"column3\": [\"a\", \"b\", \"c\"],\n",
    "})\n",
    "\n",
    "try:\n",
    "    schema.validate(df_bug)\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034a16c",
   "metadata": {},
   "source": [
    "Column checks allow for the DataFrame’s values to be checked against a user-provided function. `Check` objects also support grouping by a different column so that the user can make assertions about subsets of the column of interest.\n",
    "\n",
    "Column Hypotheses enable you to perform statistical hypothesis tests on a DataFrame in either wide or tidy format. See Hypothesis Testing for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8342aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'column1' failed element-wise validator number 0: <Check <lambda>: range checker [0, 10]> failure cases: -20, 30\n"
     ]
    }
   ],
   "source": [
    "simple_schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(\n",
    "        int,\n",
    "        pa.Check(\n",
    "            lambda x: 0 <= x <= 10,\n",
    "            element_wise=True,\n",
    "            error=\"range checker [0, 10]\"\n",
    "        )\n",
    "    )\n",
    "})\n",
    "\n",
    "df_bug = pd.DataFrame({\n",
    "    \"column1\": [-20, 5, 10, 30],\n",
    "})\n",
    "\n",
    "try:\n",
    "    simple_schema.validate(df_bug)\n",
    "except pa.errors.SchemaError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd7f32",
   "metadata": {},
   "source": [
    "### 1.2.2 Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9a248",
   "metadata": {},
   "source": [
    "By default, SeriesSchema/Column objects assume that values are not nullable. In order to accept null values, you need to explicitly specify `nullable=True`, or else you’ll get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f14926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-nullable series 'column1' contains null values:\n",
      "2   NaN\n",
      "Name: column1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"column1\": [5, 1, np.nan]})\n",
    "\n",
    "non_null_schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(float, pa.Check(lambda x: x > 0))\n",
    "})\n",
    "\n",
    "try:\n",
    "    non_null_schema.validate(df)\n",
    "except pa.errors.SchemaError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92a5f0",
   "metadata": {},
   "source": [
    "Setting `nullable=True` allows for null values in the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4597150b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column1\n",
       "0      5.0\n",
       "1      1.0\n",
       "2      NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(float, pa.Check(lambda x: x > 0), nullable=True)\n",
    "})\n",
    "\n",
    "null_schema.validate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea1c8c",
   "metadata": {},
   "source": [
    "### 1.2.3 Coercing types on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50040cfb",
   "metadata": {},
   "source": [
    "If you specify `Column(dtype, ..., coerce=True)` as part of the DataFrameSchema definition, calling `schema.validate` will first coerce the column into the specified `dtype` before applying validation checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c3f5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "df = pd.DataFrame({\"column1\": [1, 2, 3]})\n",
    "schema = pa.DataFrameSchema({\"column1\": pa.Column(str, coerce=True)})\n",
    "\n",
    "validated_df = schema.validate(df)\n",
    "assert isinstance(validated_df.column1.iloc[0], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "471404f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while coercing 'column1' to type int64: Could not coerce <class 'pandas.core.series.Series'> data_container into type int64:\n",
      "   index  failure_case\n",
      "0      3           NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\"column1\": [1., 2., 3, np.nan]})\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int, coerce=True, nullable=True)\n",
    "})\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "except pa.errors.SchemaError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cda9a3",
   "metadata": {},
   "source": [
    "The best way to handle this case is to simply specify the column as a `Float` or `Object`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d7a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column1    object\n",
      "dtype: object\n",
      "column1    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "schema_object = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(object, coerce=True, nullable=True)\n",
    "})\n",
    "schema_float = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(float, coerce=True, nullable=True)\n",
    "})\n",
    "\n",
    "print(schema_object.validate(df).dtypes)\n",
    "print(schema_float.validate(df).dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8800d",
   "metadata": {},
   "source": [
    "### 1.2.4 Required columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6579e2",
   "metadata": {},
   "source": [
    "By default all columns specified in the schema are required, meaning that if a column is missing in the input DataFrame an exception will be thrown. If you want to make a column optional, specify `required=False` in the column constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0675718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pandera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column2\n",
       "0    hello\n",
       "1  pandera"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"column2\": [\"hello\", \"pandera\"]})\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int, required=False),\n",
    "    \"column2\": pa.Column(str)\n",
    "})\n",
    "\n",
    "schema.validate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71f41c",
   "metadata": {},
   "source": [
    "Since `required=True` by default, missing columns would raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c69021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column 'column1' not in dataframe. Columns in dataframe: ['column2']\n"
     ]
    }
   ],
   "source": [
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int),\n",
    "    \"column2\": pa.Column(str),\n",
    "})\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "except pa.errors.SchemaError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf5fdb",
   "metadata": {},
   "source": [
    "### 1.2.5 Column regex pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dc48c",
   "metadata": {},
   "source": [
    "In the case that your dataframe has multiple columns that share common statistical properties, you might want to specify a regex pattern that matches a set of meaningfully grouped columns that have `str` names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb7a94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_var_1</th>\n",
       "      <th>cat_var_2</th>\n",
       "      <th>num_var_1</th>\n",
       "      <th>num_var_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>6.804147</td>\n",
       "      <td>24.743304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>3.684308</td>\n",
       "      <td>22.774633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>5.911288</td>\n",
       "      <td>28.416588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>4.790627</td>\n",
       "      <td>21.951250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>4.504166</td>\n",
       "      <td>28.563142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat_var_1 cat_var_2  num_var_1  num_var_2\n",
       "0         A         A   6.804147  24.743304\n",
       "1         A         C   3.684308  22.774633\n",
       "2         A         C   5.911288  28.416588\n",
       "3         C         A   4.790627  21.951250\n",
       "4         C         B   4.504166  28.563142"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "categories = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "dataframe = pd.DataFrame({\n",
    "    \"cat_var_1\": np.random.choice(categories, size=100),\n",
    "    \"cat_var_2\": np.random.choice(categories, size=100),\n",
    "    \"num_var_1\": np.random.uniform(0, 10, size=100),\n",
    "    \"num_var_2\": np.random.uniform(20, 30, size=100),\n",
    "})\n",
    "\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"num_var_.+\": pa.Column(\n",
    "        float,\n",
    "        checks=pa.Check.greater_than_or_equal_to(0),\n",
    "        regex=True,\n",
    "    ),\n",
    "    \"cat_var_.+\": pa.Column(\n",
    "        pa.Category,\n",
    "        checks=pa.Check.isin(categories),\n",
    "        coerce=True,\n",
    "        regex=True,\n",
    "    ),\n",
    "})\n",
    "\n",
    "schema.validate(dataframe).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20fb12",
   "metadata": {},
   "source": [
    "You can also regex pattern match on `pd.MultiIndex` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ea8f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>cat_var_1</th>\n",
       "      <th>cat_var_2</th>\n",
       "      <th>num_var_1</th>\n",
       "      <th>num_var_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>6.804147</td>\n",
       "      <td>4.743304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>3.684308</td>\n",
       "      <td>2.774633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>5.911288</td>\n",
       "      <td>8.416588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>4.790627</td>\n",
       "      <td>1.951250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>4.504166</td>\n",
       "      <td>8.563142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat_var_1 cat_var_2 num_var_1 num_var_2\n",
       "         y1        y2        x1        x2\n",
       "0         A         A  6.804147  4.743304\n",
       "1         A         C  3.684308  2.774633\n",
       "2         A         C  5.911288  8.416588\n",
       "3         C         A  4.790627  1.951250\n",
       "4         C         B  4.504166  8.563142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "dataframe = pd.DataFrame({\n",
    "    (\"cat_var_1\", \"y1\"): np.random.choice(categories, size=100),\n",
    "    (\"cat_var_2\", \"y2\"): np.random.choice(categories, size=100),\n",
    "    (\"num_var_1\", \"x1\"): np.random.uniform(0, 10, size=100),\n",
    "    (\"num_var_2\", \"x2\"): np.random.uniform(0, 10, size=100),\n",
    "})\n",
    "\n",
    "schema = pa.DataFrameSchema({\n",
    "    (\"num_var_.+\", \"x.+\"): pa.Column(\n",
    "        float,\n",
    "        checks=pa.Check.greater_than_or_equal_to(0),\n",
    "        regex=True,\n",
    "    ),\n",
    "    (\"cat_var_.+\", \"y.+\"): pa.Column(\n",
    "        pa.Category,\n",
    "        checks=pa.Check.isin(categories),\n",
    "        coerce=True,\n",
    "        regex=True,\n",
    "    ),\n",
    "})\n",
    "\n",
    "schema.validate(dataframe).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349004f5",
   "metadata": {},
   "source": [
    "### 1.2.6 Validating the joint uniqueness of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e65b116",
   "metadata": {},
   "source": [
    "In some cases you might want to ensure that a group of columns are unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfbed618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns '('a', 'c')' not unique:\n",
      "   a  c\n",
      "0  1  3\n",
      "1  1  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    columns={col: pa.Column(int) for col in [\"a\", \"b\", \"c\"]},\n",
    "    unique=[\"a\", \"c\"],\n",
    ")\n",
    "df = pd.DataFrame.from_records([\n",
    "    {\"a\": 1, \"b\": 2, \"c\": 3},\n",
    "    {\"a\": 1, \"b\": 2, \"c\": 3},\n",
    "])\n",
    "try:\n",
    "    schema.validate(df)\n",
    "except pa.errors.SchemaError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a613a5c",
   "metadata": {},
   "source": [
    "To control how unique errors are reported, the `report_duplicates` argument accepts:\n",
    "* `exclude_first`: (default) report all duplicates except first occurrence\n",
    "* `exclude_last`: report all duplicates except last occurrence\n",
    "* `all`: report all duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b91b96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns '('a', 'c')' not unique:\n",
      "   a  c\n",
      "1  1  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    columns={col: pa.Column(int) for col in [\"a\", \"b\", \"c\"]},\n",
    "    unique=[\"a\", \"c\"],\n",
    "    report_duplicates = \"exclude_first\",\n",
    ")\n",
    "df = pd.DataFrame.from_records([\n",
    "    {\"a\": 1, \"b\": 2, \"c\": 3},\n",
    "    {\"a\": 1, \"b\": 2, \"c\": 3},\n",
    "])\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "except pa.errors.SchemaError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33461a12",
   "metadata": {},
   "source": [
    "# 2. Handling errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69fe6a",
   "metadata": {},
   "source": [
    "## 2.1 Missing and required columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b95fa6",
   "metadata": {},
   "source": [
    "### 2.1.1 Handling dataframe columns not in the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1574f84",
   "metadata": {},
   "source": [
    "By default, columns that aren’t specified in the schema aren’t checked. If you want to check that the DataFrame only contains columns in the schema, specify `strict=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04b6f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column 'column2' not in DataFrameSchema {'column1': <Schema Column(name=column1, type=DataType(int64))>}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\"column1\": pa.Column(int)},\n",
    "    strict=True)\n",
    "\n",
    "df = pd.DataFrame({\"column2\": [1, 2, 3]})\n",
    "\n",
    "try:\n",
    "    schema.validate(df)\n",
    "except pa.errors.SchemaError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51776c4e",
   "metadata": {},
   "source": [
    "Alternatively, if your DataFrame contains columns that are not in the schema, and you would like these to be dropped on validation, you can specify `strict='filter'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3a68ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column2\n",
       "0    keep\n",
       "1      me"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"column1\": [\"drop\", \"me\"],\"column2\": [\"keep\", \"me\"]})\n",
    "schema = pa.DataFrameSchema({\"column2\": pa.Column(str)}, strict='filter')\n",
    "\n",
    "schema.validate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a476bf",
   "metadata": {},
   "source": [
    "### 2.1.2 Adding missing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a2ee98",
   "metadata": {},
   "source": [
    "When loading raw data into a form that’s ready for data processing, it’s often useful to have guarantees that the columns specified in the schema are present, even if they’re missing from the raw data. This is where it’s useful to specify `add_missing_columns=True` in your schema definition.\n",
    "\n",
    "When you call `schema.validate(data)`, the schema will add any missing columns to the dataframe, defaulting to the default value if supplied at the column-level, or to `NaN` if the column is nullable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec253c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b   c\n",
       "0  1  1 NaN\n",
       "1  2  1 NaN\n",
       "2  3  1 NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandera.pandas as pa\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    columns={\n",
    "        \"a\": pa.Column(int),\n",
    "        \"b\": pa.Column(int, default=1),\n",
    "        \"c\": pa.Column(float, nullable=True),\n",
    "    },\n",
    "    add_missing_columns=True,\n",
    "    coerce=True,\n",
    ")\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "schema.validate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada51750",
   "metadata": {},
   "source": [
    "## 2.2 Error reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaadd44",
   "metadata": {},
   "source": [
    "If the dataframe is validated lazily with `lazy=True`, errors will be aggregated into an error report. The error report groups `DATA` and `SCHEMA` errors to to give an overview of error sources within a dataframe. Take the following schema and dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9800bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"SCHEMA\": {\n",
      "        \"COLUMN_NOT_IN_SCHEMA\": [\n",
      "            {\n",
      "                \"schema\": \"MySchema\",\n",
      "                \"column\": \"MySchema\",\n",
      "                \"check\": \"column_in_schema\",\n",
      "                \"error\": \"column 'extra_column' not in DataFrameSchema {'id': <Schema Column(name=id, type=DataType(int64))>}\"\n",
      "            }\n",
      "        ],\n",
      "        \"SERIES_CONTAINS_NULLS\": [\n",
      "            {\n",
      "                \"schema\": \"MySchema\",\n",
      "                \"column\": \"id\",\n",
      "                \"check\": \"not_nullable\",\n",
      "                \"error\": \"non-nullable series 'id' contains null values:1   NaNName: id, dtype: float64\"\n",
      "            }\n",
      "        ],\n",
      "        \"WRONG_DATATYPE\": [\n",
      "            {\n",
      "                \"schema\": \"MySchema\",\n",
      "                \"column\": \"id\",\n",
      "                \"check\": \"dtype('int64')\",\n",
      "                \"error\": \"expected series 'id' to have type int64, got float64\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"DATA\": {\n",
      "        \"DATAFRAME_CHECK\": [\n",
      "            {\n",
      "                \"schema\": \"MySchema\",\n",
      "                \"column\": \"id\",\n",
      "                \"check\": \"less_than(10)\",\n",
      "                \"error\": \"Column 'id' failed element-wise validator number 0: less_than(10) failure cases: 30.0\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "schema = pa.DataFrameSchema(\n",
    "    {\"id\": pa.Column(int, pa.Check.lt(10))},\n",
    "    name=\"MySchema\",\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\"id\": [1, None, 30], \"extra_column\": [1, 2, 3]})\n",
    "\n",
    "try:\n",
    "    schema.validate(df, lazy=True)\n",
    "except pa.errors.SchemaErrors as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ebab1",
   "metadata": {},
   "source": [
    "Validating the above dataframe will result in data level errors, namely the `id` column having a value which fails a check, as well as schema level errors, such as the extra column and the `None` value.\n",
    "\n",
    "This error report can be useful for debugging, with each item in the various lists corresponding to a `SchemaError`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10644ab",
   "metadata": {},
   "source": [
    "# 3. Synthesize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b27cd",
   "metadata": {},
   "source": [
    "`pandera` provides a utility for generating synthetic data purely from pandera schema or schema component objects. Under the hood, the schema metadata is collected to create a data-generating strategy using [hypothesis](https://hypothesis.readthedocs.io/en/latest/), which is a property-based testing library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36eb13c",
   "metadata": {},
   "source": [
    "## 3.1 Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c9bc8",
   "metadata": {},
   "source": [
    "Once you’ve defined a schema, it’s easy to generate examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "598ab096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>column3</th>\n",
       "      <th>column4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>foo</td>\n",
       "      <td>k.qfkx@axa-direct.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>foo</td>\n",
       "      <td>yprw.wsgw@axa-direct.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>foo</td>\n",
       "      <td>rlcfk.iavdc@axa-direct.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column1  column2 column3                     column4\n",
       "0       10     0.25     foo       k.qfkx@axa-direct.com\n",
       "1       10     0.25     foo    yprw.wsgw@axa-direct.com\n",
       "2       10     0.25     foo  rlcfk.iavdc@axa-direct.com"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandera.pandas as pa\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"column1\": pa.Column(int, pa.Check.eq(10)),\n",
    "        \"column2\": pa.Column(float, pa.Check.eq(0.25)),\n",
    "        \"column3\": pa.Column(str, pa.Check.eq(\"foo\")),\n",
    "        \"column4\": pa.Column(str, pa.Check.str_matches(r\"[a-z]+\\.[a-z]+@axa\\-direct\\.com\"))\n",
    "    }\n",
    ")\n",
    "schema.example(size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69c051",
   "metadata": {},
   "source": [
    "## 3.2 Usage in unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b68f019",
   "metadata": {},
   "source": [
    "The `example` method is available for all schemas and schema components, and is primarily meant to be used interactively. It could be used in a script to generate test cases, but `hypothesis` recommends against doing this and instead using the `strategy` method to create a `hypothesis` strategy that can be used in `pytest` unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c690068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypothesis\n",
    "import pandera.pandas as pa\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"column1\": pa.Column(int, pa.Check.eq(10)),\n",
    "        \"column2\": pa.Column(float, pa.Check.eq(0.25)),\n",
    "        \"column3\": pa.Column(str, pa.Check.eq(\"foo\")),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def processing_fn(df):\n",
    "    return df.assign(column4=df.column1 * df.column2)\n",
    "\n",
    "@hypothesis.given(schema.strategy(size=5))\n",
    "def test_processing_fn(dataframe):\n",
    "    result = processing_fn(dataframe)\n",
    "    assert \"column4\" in result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2307dcc",
   "metadata": {},
   "source": [
    "The above example is trivial, but you get the idea! Schema objects can create a `strategy` that can then be collected by a [pytest](https://docs.pytest.org/en/latest/) runner. We could also run the tests explicitly ourselves, or run it as a `unittest.TestCase`. For more information on testing with hypothesis, see the [hypothesis quick start guide](https://hypothesis.readthedocs.io/en/latest/quickstart.html#running-tests).\n",
    "\n",
    "A more practical example involves using [schema transformations](https://pandera.readthedocs.io/en/stable/dataframe_schemas.html#dataframe-schema-transformations). We can modify the function above to make sure that `processing_fn` actually outputs the correct result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1f74ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_schema = schema.add_columns({\"column4\": pa.Column(float)})\n",
    "\n",
    "@pa.check_output(out_schema)\n",
    "def processing_fn(df):\n",
    "    return df.assign(column4=df.column1 * df.column2)\n",
    "\n",
    "@hypothesis.given(schema.strategy(size=5))\n",
    "def test_processing_fn(dataframe):\n",
    "    processing_fn(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ee312",
   "metadata": {},
   "source": [
    "# 4. Supported features by DataFrame backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a81933",
   "metadata": {},
   "source": [
    "Currently, pandera provides four validation backends: `pandas`, `pyspark`, `polars`, and `ibis`. The table below shows which of pandera’s features are available for the [supported dataframe libraries](https://pandera.readthedocs.io/en/stable/supported_libraries.html#dataframe-libraries):\n",
    "\n",
    "![Supported features](../docs/pandera-libraries-compatibility.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1920367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
